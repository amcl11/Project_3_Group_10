{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth', 400)\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, Float, String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning accidents.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_accidents_path = \"Resources/ACCIDENT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the csv file into a dataframe\n",
    "vic_accidents_df = pd.read_csv(vic_accidents_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the dataframe\n",
    "vic_accidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vic_accidents_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_accidents_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the information about the dataframe\n",
    "vic_accidents_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the null values in the dataframe\n",
    "vic_accidents_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unwanted columns\n",
    "vic_accidents_clean_df = vic_accidents_df[[\"ACCIDENT_NO\",\"ACCIDENTDATE\",\"Accident Type Desc\",\"Day Week Description\",\"SEVERITY\",\"NODE_ID\"]]\n",
    "vic_accidents_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the datatype of the \"ACCIDENT_NO\"  column to string\n",
    "vic_accidents_clean_df[\"ACCIDENT_NO\"]= vic_accidents_clean_df[\"ACCIDENT_NO\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if the new dataframe has null values\n",
    "vic_accidents_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_accidents_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Persons.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_path = \"Resources/PERSON.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = pd.read_csv(persons_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the length of the dataframe\n",
    "print(len(persons_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the dataframe\n",
    "persons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the info of the dataframe\n",
    "persons_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates\n",
    "clean_persons_df = persons_df.drop_duplicates(subset=[\"ACCIDENT_NO\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiding if the dataframe has null values\n",
    "clean_persons_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unwanted columns\n",
    "persons_cleaned_df = clean_persons_df[[\"ACCIDENT_NO\",\"SEX\",\"Age Group\"]]\n",
    "persons_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the dattype of the accident_no column to string\n",
    "persons_cleaned_df[\"ACCIDENT_NO\"]= persons_cleaned_df[\"ACCIDENT_NO\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the vic_accidents_clean_df and persons_cleaned_df\n",
    "combined_data = pd.merge(vic_accidents_clean_df,persons_cleaned_df, how = \"left\", on = \"ACCIDENT_NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if the combined dataframe has null values\n",
    "combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "combined_clean_data = combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if null value exist\n",
    "combined_clean_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Node csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_path = \"Resources/NODE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.read_csv(node_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of dataframe\n",
    "print(len(node_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if null values exist\n",
    "node_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding unique values in the node id column\n",
    "print(len(node_df[\"NODE_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the datatype of the \"accident_no\" column to str \n",
    "node_df[\"ACCIDENT_NO\"] = node_df[\"ACCIDENT_NO\"].astype(\"string\")\n",
    "node_df[\"Postcode No\"] = node_df[\"Postcode No\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unwanted columns\n",
    "node_clean_df = node_df[[\"ACCIDENT_NO\",\"Lat\",\"Long\",\"LGA_NAME\",\"Postcode No\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "node_final_df = node_clean_df.rename(columns = {\"Postcode No\":\"Accident Postcode\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dataframe to previously merged data called combined_data\n",
    "node_combined_data = pd.merge(combined_data,node_final_df,how = \"left\" , on = \"ACCIDENT_NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of the new combined dataframe\n",
    "print(len(node_combined_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if null values exist\n",
    "node_combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "node_final_combined_data = node_combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming null values were dropped\n",
    "node_final_combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_final_combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Vehicle csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_path = \"Resources/VEHICLE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_df = pd.read_csv(vehicle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of the dataframe\n",
    "print(len(vehicle_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unwanted columns\n",
    "vehicle_clean_df = vehicle_df[[\"ACCIDENT_NO\",\"VEHICLE_BODY_STYLE\",\"VEHICLE_MAKE\",\"VEHICLE_TYPE\",\"VEHICLE_POWER\",\n",
    "                               \"OWNER_POSTCODE\",\"VEHICLE_YEAR_MANUF\"]]\n",
    "vehicle_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #changig the datatype of the accident_no column to str\n",
    "vehicle_clean_df[\"ACCIDENT_NO\"] = vehicle_clean_df[\"ACCIDENT_NO\"].astype(\"string\")\n",
    "vehicle_clean_df[\"VEHICLE_TYPE\"] = vehicle_clean_df[\"VEHICLE_TYPE\"].astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if null values exist\n",
    "vehicle_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values\n",
    "vehicle_final_clean_df = vehicle_clean_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vehicle_final_clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming null values were dropped\n",
    "vehicle_final_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of the \".0\" in the owner_postcode and vehicle_year_manuf columns\n",
    "vehicle_final_clean_df[\"OWNER_POSTCODE\"] = vehicle_final_clean_df[\"OWNER_POSTCODE\"].astype(\"int\").round()\n",
    "vehicle_final_clean_df[\"VEHICLE_YEAR_MANUF\"] = vehicle_final_clean_df[\"VEHICLE_YEAR_MANUF\"].astype(\"int\").round()\n",
    "vehicle_final_clean_df[\"VEHICLE_POWER\"]  = [float(str(i).replace(\",\", \"\"))for i in vehicle_final_clean_df[\"VEHICLE_POWER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changig the datatype of the owner_postcode and vehicle_year_manuf columns to str\n",
    "vehicle_final_clean_df[\"OWNER_POSTCODE\"] = vehicle_final_clean_df[\"OWNER_POSTCODE\"].astype(\"string\")\n",
    "vehicle_final_clean_df[\"VEHICLE_YEAR_MANUF\"] = vehicle_final_clean_df[\"VEHICLE_YEAR_MANUF\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_final_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dataframe to the previously merged dataframe called node_final_combined_data\n",
    "vehicle_combined_data = pd.merge(node_final_combined_data,vehicle_final_clean_df,how =\"left\",on = \"ACCIDENT_NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if null values exist\n",
    "vehicle_combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "final_df = vehicle_combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that nulls value dont exist\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns for easy readability\n",
    "final_rename_df = final_df.rename(columns = {\"Accident Type Desc\":\"ACCIDENT_TYPE_DESC\",\"Day Week Description\":\"DAY_WEEK_DESC\",\n",
    "                                            \"Age Group\":\"AGE_GROUP\",\"Lat\":\"LAT\",\"Long\":\"LONG\",\n",
    "                                             \"Accident Postcode\":\"ACCIDENT_POSTCODE\",\"ACCIDENTDATE\":\"ACCIDENT_DATE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rename_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding if the accident columns had dupliactes\n",
    "print(len(final_rename_df[\"ACCIDENT_NO\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the duplicates\n",
    "final_clean_df = final_rename_df.drop_duplicates(subset=[\"ACCIDENT_NO\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring we only have unique valuess in the accident_no column\n",
    "print(len(final_clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with A value of uknown in the agegroup column\n",
    "final_clean_df = final_clean_df.drop(final_clean_df[final_clean_df['AGE_GROUP'] == 'unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with A value of 12May in the agegroup column\n",
    "final_clean_df = final_clean_df.drop(final_clean_df[final_clean_df['AGE_GROUP'] == '12-May'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the acccident_date column to get the accident year,month and day\n",
    "final_clean_df[[\"DAY\", \"MONTH\",\"YEAR\"]] = final_clean_df[\"ACCIDENT_DATE\"].str.split('/', n=2, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping of the month and day columns\n",
    "final_updated_df = final_clean_df.drop(columns = [\"DAY\",\"MONTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the year column to accident_year\n",
    "final_updated_renamed_df = final_updated_df.rename(columns = {\"YEAR\":\"ACCIDENT_YEAR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_updated_renamed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging the columns\n",
    "FINAL_RESULT_DF = final_updated_renamed_df[[\"ACCIDENT_NO\",\"ACCIDENT_DATE\",\"ACCIDENT_YEAR\",\"ACCIDENT_TYPE_DESC\",\n",
    "                                          \"DAY_WEEK_DESC\", \"SEVERITY\",\"NODE_ID\",\"SEX\",\"AGE_GROUP\",\"LAT\",\"LONG\",\n",
    "                                           \"LGA_NAME\",\"ACCIDENT_POSTCODE\",\"VEHICLE_BODY_STYLE\",\"VEHICLE_MAKE\",\"VEHICLE_TYPE\",\n",
    "                                           \"VEHICLE_POWER\",\"OWNER_POSTCODE\",\"VEHICLE_YEAR_MANUF\"]]\n",
    "FINAL_RESULT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_RESULT_DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the data to csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_RESULT_DF.to_csv(\"Resources/final.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the dataframe into Sqlite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine\n",
    "engine = create_engine('sqlite:///vic_accidents.db')\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the schema for the 'accidents' table\n",
    "accidents = Table(\n",
    "    'accidents', metadata,\n",
    "    Column('ACCIDENT_NO', String, primary_key=True),\n",
    "    Column('ACCIDENT_DATE', String),\n",
    "    Column('ACCIDENT_YEAR', String),\n",
    "    Column('ACCIDENT_TYPE_DESC', String),\n",
    "    Column('DAY_WEEK_DESC', String),\n",
    "    Column('SEVERITY', Integer),\n",
    "    Column('NODE_ID', Integer),\n",
    "    Column('SEX', String),\n",
    "    Column('AGE_GROUP', String),\n",
    "    Column('LAT', Float),\n",
    "    Column('LONG', Float),\n",
    "    Column('LGA_NAME', String),\n",
    "    Column('ACCIDENT_POSTCODE', String),\n",
    "    Column('VEHICLE_BODY_STYLE', String),\n",
    "    Column('VEHICLE_MAKE', String),\n",
    "    Column('VEHICLE_TYPE', String),\n",
    "    Column('VEHICLE_POWER', Float),\n",
    "    Column('OWNER_POSTCODE', String),\n",
    "    Column('VEHICLE_YEAR_MANUF', String)\n",
    ")\n",
    "\n",
    "# Create the table\n",
    "metadata.create_all(engine)\n",
    "# Insert DataFrame into SQLite, without creating a new table\n",
    "FINAL_RESULT_DF.to_sql('accidents',engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
